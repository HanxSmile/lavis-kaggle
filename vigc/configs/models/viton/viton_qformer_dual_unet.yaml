model:
  load_finetuned: False
  finetuned: ""
  arch: viton_qformer_dual_unet
  model_type: default

  pretrained_model_name_or_path: stable-diffusion-v1-5/stable-diffusion-v1-5
  tokenizer_name: Null
  revision: Null
  variant: Null
  gradient_checkpointing: False
  enable_xformers_memory_efficient_attention: False
  compute_dtype: fp16
  proportion_empty_prompts: 0
  lora_config:
    lora_r: 8
    lora_alpha: 16
    lora_dropout: 0.1
    target_modules: [ "q_proj", "k_proj", "v_proj", "out_proj", "mlp.fc1", "mlp.fc2" ]
  # q-former
  num_query_token: 32
  max_txt_len: 128
  qformer_model_name_or_path: bert-base-uncased
  # q-former visual encoder
  vit_model: eva_clip_g
  vit_model_ckpt: Null
  img_size: 224
  drop_path_rate: 0
  use_grad_checkpoint: False
  vit_precision: fp16
  freeze_qformer: True
  freeze_text_encoder: True
  freeze_vit: True
  freeze_vit_ln: True